# =============================================================================
# Discord Configuration
# =============================================================================
DISCORD_BOT_TOKEN=your_discord_bot_token_here
# Display name used in bot responses (default: Clippy)
BOT_NAME=Clippy

# =============================================================================
# OpenClaw Configuration
# =============================================================================
# URL of the OpenClaw Gateway API (default port is 18789)
# Uses the OpenAI-compatible /v1/chat/completions endpoint
# IMPORTANT: The gateway HTTP API must be enabled on the OpenClaw side:
#   Set gateway.bind to "lan" in openclaw.json or OPENCLAW_GATEWAY_BIND=lan
OPENCLAW_URL=http://localhost:18789
# Gateway auth token (must match OPENCLAW_GATEWAY_TOKEN on the OpenClaw side)
# Required when gateway.bind != "loopback"
OPENCLAW_API_KEY=
# Agent ID to use for voice sessions.
# RECOMMENDED: Create a dedicated voice agent in OpenClaw with a system prompt
# optimized for spoken responses (short, no markdown, conversational).
# See README.md "Create a Voice Agent" section for the recommended system prompt.
# Set to "default" to use the default agent (less ideal for voice).
OPENCLAW_AGENT_ID=voice

# =============================================================================
# Text-to-Speech Configuration
# =============================================================================
# TTS provider: "elevenlabs" or "local" (Coqui/Piper)
TTS_PROVIDER=local
# ElevenLabs API key (required if TTS_PROVIDER=elevenlabs)
ELEVENLABS_API_KEY=
# ElevenLabs voice ID
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM
# Piper voice model — use a model name or full path to .onnx file.
# Model names are auto-resolved to /opt/piper/<name>.onnx and downloaded
# from HuggingFace if not present. Examples:
#   en_US-hfc_male-medium   (default female, good quality)
#   en_US-lessac-high     (same voice, higher quality)
#   en_US-ryan-high       (male voice)
#   en_GB-cori-high       (British female)
#   en_US-joe-medium      (male voice)
# Full list: https://rhasspy.github.io/piper-samples/
LOCAL_TTS_MODEL=en_US-hfc_male-medium

# =============================================================================
# Speech-to-Text Configuration
# =============================================================================
# STT model size: tiny, base, small, medium, large-v2, large-v3
STT_MODEL_SIZE=base
# Device for Whisper inference: cpu, cuda, auto
STT_DEVICE=auto
# Compute type: int8, float16, float32
STT_COMPUTE_TYPE=int8
# Keep Whisper model loaded between voice sessions (true/false)
# When true, the model is loaded once at startup and stays in memory,
# making rejoins instant. When false, the model is loaded per-session
# (saves memory when idle but adds delay on join).
STT_PRELOAD=true

# =============================================================================
# Wake Word Configuration
# =============================================================================
# Enable wake word detection (true/false)
# NOTE: Disabled by default — enable once the base voice loop is stable.
WAKE_WORD_ENABLED=false
# Custom wake word model path (leave empty to use defaults)
WAKE_WORD_MODEL_PATH=
# Wake word sensitivity threshold (0.0-1.0, higher = more sensitive)
WAKE_WORD_THRESHOLD=0.5

# =============================================================================
# Voice Bridge (DAVE E2EE)
# =============================================================================
# WebSocket URL for the Node.js voice bridge that handles Discord DAVE encryption.
# Default: ws://localhost:9876 (embedded bridge, runs inside the same container)
# For docker-compose two-container mode: ws://voice-bridge:9876
# VOICE_BRIDGE_URL=ws://localhost:9876
# Port for the embedded voice bridge (only relevant in single-container mode)
# BRIDGE_PORT=9876

# =============================================================================
# Voice Channel Behavior
# =============================================================================
# Auto-join when authorized users enter a voice channel (true/false)
AUTO_JOIN_ENABLED=true
# Inactivity timeout in seconds before leaving voice channel
INACTIVITY_TIMEOUT=300
# Maximum session duration in seconds (0 = unlimited)
MAX_SESSION_DURATION=0

# =============================================================================
# Authorization
# =============================================================================
# Comma-separated list of Discord user IDs that are authorized
AUTHORIZED_USER_IDS=
# Whether to require wake word from non-authorized users (true/false)
REQUIRE_WAKE_WORD_FOR_UNAUTHORIZED=true

# =============================================================================
# Thinking Sound (played while waiting for AI response)
# =============================================================================
# Tune these to change the "thinking" tone. Use the interactive tuner:
#   open docs/thinking-sound-tuner.html in a browser to preview changes live.
# Primary tone frequency in Hz (default 130 = C3)
# THINKING_TONE1_HZ=130
# Secondary tone frequency in Hz (default 130 = C3)
# THINKING_TONE2_HZ=130
# Mix ratio: tone1 vs tone2 (0.0-1.0, default 0.7 = 70% tone1)
# THINKING_TONE_MIX=0.7
# Pulse/fade speed in Hz (lower = slower breathing, default 0.3)
# THINKING_PULSE_HZ=0.3
# Volume (0.0-1.0, default 0.4 = 40%)
# THINKING_VOLUME=0.4
# Loop clip duration in seconds (default 2.5)
# THINKING_DURATION=2.5

# =============================================================================
# Logging & Debugging
# =============================================================================
LOG_LEVEL=INFO
# Enable verbose debug logging for the voice pipeline only (true/false)
# Logs detailed timing, audio stats, RMS values, STT/TTS/LLM step durations,
# and pipeline flow without enabling DEBUG for noisy libraries like discord.py.
# Useful for diagnosing why the bot isn't responding or where delays occur.
DEBUG_VOICE_PIPELINE=false

# =============================================================================
# Directories (usually only need to change in Docker)
# =============================================================================
# Where persistent data is stored
# In Docker, set via volume mount: -v /host/path:/app/data
# DATA_DIR=data
# Where AI models are cached (Whisper, wake word, TTS)
# In Docker, set via volume mount: -v /host/path:/app/models
# MODELS_DIR=models
# Where Piper TTS models are stored (container default: /opt/piper)
# PIPER_MODEL_DIR=/opt/piper
